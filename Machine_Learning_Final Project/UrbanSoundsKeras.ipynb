{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "datanpy = np.load('./urban-processed/data70.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list_npy = np.load('./urban-processed/files_list70.npy',allow_pickle=True)\n",
    "times_list_npy = np.load('./urban-processed/times_list70.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "newdata = []\n",
    "for i in range(len(datanpy)):\n",
    "    if i%10 ==0:\n",
    "        print(i)\n",
    "    for j in range(len(datanpy[i])):\n",
    "        for k in range(len(datanpy[i][j])):\n",
    "            newdata.append((datanpy[i][j][k]+datanpy[i][j][k])/2)\n",
    "'''\n",
    "datanpy =datanpy[:,0:100,0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8732, 70, 70)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[6.79378591e-13, 3.17790017e-10, 1.14418364e-10, ...,\n",
       "         1.16217524e-08, 7.54488916e-10, 5.26129673e-09],\n",
       "        [1.68355798e-11, 3.55363267e-10, 8.35323338e-11, ...,\n",
       "         3.86343046e-09, 4.37743231e-10, 2.11693263e-09],\n",
       "        [6.26813115e-11, 1.08135312e-09, 6.54149845e-10, ...,\n",
       "         1.24940192e-09, 3.76949028e-10, 4.86793161e-10],\n",
       "        ...,\n",
       "        [8.06595730e-14, 1.93347251e-13, 2.15119229e-08, ...,\n",
       "         4.39520989e-11, 5.42613567e-12, 2.30496299e-11],\n",
       "        [5.58384888e-14, 1.81193656e-13, 1.09083551e-08, ...,\n",
       "         3.99611802e-11, 2.92926208e-12, 1.71715558e-11],\n",
       "        [2.04783727e-13, 2.83981941e-14, 6.74947254e-09, ...,\n",
       "         5.43933605e-12, 6.09059764e-12, 1.85631684e-11]],\n",
       "\n",
       "       [[5.69664038e-10, 1.63528580e-10, 1.36504461e-10, ...,\n",
       "         3.65890457e-10, 1.62544242e-10, 3.52759988e-10],\n",
       "        [9.26960106e-11, 4.55008670e-10, 3.78689163e-10, ...,\n",
       "         6.10788989e-11, 7.88580520e-11, 6.17655649e-11],\n",
       "        [4.82548224e-10, 1.14559653e-10, 1.09209375e-09, ...,\n",
       "         4.80958107e-10, 3.51400409e-10, 4.82174162e-11],\n",
       "        ...,\n",
       "        [3.26927857e-13, 1.75904742e-13, 1.77891386e-14, ...,\n",
       "         1.60542979e-13, 1.38360677e-13, 2.28638343e-13],\n",
       "        [3.42887678e-14, 3.11714765e-14, 1.20588703e-15, ...,\n",
       "         9.49217037e-14, 1.41719346e-13, 6.70091220e-14],\n",
       "        [1.37158402e-14, 2.34316948e-15, 4.98695527e-14, ...,\n",
       "         8.35548604e-14, 1.60335985e-14, 2.46241998e-14]],\n",
       "\n",
       "       [[1.86022049e-07, 4.96136714e-08, 1.57847613e-09, ...,\n",
       "         1.19147266e-07, 1.25953846e-07, 1.74151236e-08],\n",
       "        [5.13166718e-08, 6.14183815e-09, 7.13238135e-10, ...,\n",
       "         2.86901116e-08, 2.83188779e-08, 3.05380321e-09],\n",
       "        [3.02777039e-08, 8.94985774e-09, 5.42582068e-09, ...,\n",
       "         1.15163443e-08, 1.34177949e-08, 2.43825737e-09],\n",
       "        ...,\n",
       "        [3.18942028e-08, 6.41383302e-09, 1.40288378e-10, ...,\n",
       "         1.34037075e-08, 7.20484792e-08, 1.11826914e-09],\n",
       "        [1.70940986e-08, 5.70569703e-10, 9.63793351e-11, ...,\n",
       "         2.68701705e-09, 1.75897448e-08, 2.46043935e-10],\n",
       "        [2.66239963e-09, 5.14007586e-11, 1.72838091e-10, ...,\n",
       "         9.53276658e-09, 1.04045288e-08, 1.39167039e-10]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[4.61426275e-09, 1.16673391e-08, 2.84398305e-09, ...,\n",
       "         1.34246392e-09, 1.58961573e-08, 1.05761755e-08],\n",
       "        [1.66411895e-09, 2.15634399e-09, 5.50423318e-10, ...,\n",
       "         4.44023568e-11, 2.11606599e-09, 6.87173818e-10],\n",
       "        [2.17603180e-09, 4.69479167e-09, 3.75025927e-10, ...,\n",
       "         5.25353580e-11, 8.38038305e-10, 6.35618058e-10],\n",
       "        ...,\n",
       "        [7.55280194e-09, 1.40112082e-08, 2.56009134e-08, ...,\n",
       "         3.88172028e-09, 2.94303271e-09, 4.82155338e-09],\n",
       "        [5.21264054e-09, 2.32211717e-09, 1.80367654e-09, ...,\n",
       "         9.84380244e-10, 6.46760978e-10, 5.82720927e-10],\n",
       "        [8.43951686e-10, 2.52046606e-09, 2.14625262e-10, ...,\n",
       "         4.13722168e-10, 9.58143148e-11, 3.24470624e-11]],\n",
       "\n",
       "       [[4.59997018e-09, 3.57717767e-08, 9.73782235e-11, ...,\n",
       "         5.45465824e-08, 7.70112951e-09, 6.75004497e-10],\n",
       "        [4.62382266e-09, 1.04606313e-09, 5.65275715e-10, ...,\n",
       "         1.76904678e-08, 3.26716570e-10, 4.03160172e-10],\n",
       "        [2.59564548e-09, 1.33254818e-09, 9.36953959e-10, ...,\n",
       "         1.25703252e-08, 2.22776339e-10, 7.64801000e-10],\n",
       "        ...,\n",
       "        [5.82538959e-08, 7.23859657e-08, 4.32910561e-08, ...,\n",
       "         1.03449366e-07, 4.53697027e-08, 9.56960946e-08],\n",
       "        [1.28594992e-08, 6.22013507e-09, 7.90522936e-09, ...,\n",
       "         7.49585993e-09, 2.26092336e-08, 2.71140888e-08],\n",
       "        [1.24798758e-08, 3.06584602e-09, 8.22986479e-09, ...,\n",
       "         4.37887522e-08, 2.41031692e-08, 8.40240588e-09]],\n",
       "\n",
       "       [[1.14467646e-09, 1.85817548e-08, 9.02499575e-10, ...,\n",
       "         7.32480609e-09, 2.41592111e-11, 1.11894201e-08],\n",
       "        [2.90086816e-10, 1.72005699e-09, 7.43447925e-12, ...,\n",
       "         1.53613633e-09, 1.26086042e-09, 2.47384535e-09],\n",
       "        [3.24089922e-10, 1.16142085e-09, 1.84098257e-11, ...,\n",
       "         1.03555875e-09, 7.96048720e-13, 9.95720728e-10],\n",
       "        ...,\n",
       "        [3.05817616e-09, 4.39572956e-09, 3.25006577e-09, ...,\n",
       "         1.13226335e-08, 3.49140161e-11, 4.68695616e-09],\n",
       "        [1.04840199e-08, 5.62497715e-10, 2.77703194e-09, ...,\n",
       "         5.01362729e-09, 2.39277417e-11, 3.37762457e-10],\n",
       "        [2.50037990e-09, 3.50948243e-10, 4.73835082e-10, ...,\n",
       "         6.68373490e-09, 2.39525830e-11, 2.99639602e-09]]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.shape(datanpy))\n",
    "datanpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'air_conditioner',\n",
       " 'car_horn',\n",
       " 'children_playing',\n",
       " 'dog_bark',\n",
       " 'drilling',\n",
       " 'engine_idling',\n",
       " 'gun_shot',\n",
       " 'jackhammer',\n",
       " 'siren',\n",
       " 'street_music'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "urban = pd.read_csv(r\"./urban-sounds/UrbanSound8K.csv\")\n",
    "set(urban['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "classIdNpy = []\n",
    "for i in range(len(files_list_npy)):\n",
    "    if i%1000 == 0:\n",
    "        print(i)\n",
    "    classIdNpy.append(urban[urban['slice_file_name']==files_list_npy[i]]['classID'].tolist()[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras,sklearn\n",
    "# suppress tensorflow compilation warnings\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import numpy as np\n",
    "seed=0\n",
    "np.random.seed(seed) # fix random seed\n",
    "tf.random.set_seed(seed)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(datanpy)\n",
    "train_size = int(.8*dataset_size)\n",
    "img_rows, img_cols = 70,70\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "X = datanpy\n",
    "Y = classIdNpy\n",
    "files_list = files_list_npy\n",
    "\n",
    "X_train = X[:train_size]\n",
    "Y_train = Y[:train_size]\n",
    "\n",
    "X_test = X[train_size:dataset_size]\n",
    "Y_test = Y[train_size:dataset_size]\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows*img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows*img_cols)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= X_train.max()\n",
    "X_test /= X_test.max()\n",
    "\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "Y_test = keras.utils.to_categorical(Y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (6985, 4900)\n",
      "Y_train shape: (6985, 10)\n",
      "\n",
      "6985 train samples\n",
      "1747 test samples\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print()\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (6985, 70, 70, 1)\n",
      "Y_train shape: (6985, 10)\n",
      "\n",
      "6985 train samples\n",
      "1747 test samples\n"
     ]
    }
   ],
   "source": [
    "# reshape data, depending on Keras backend\n",
    "if keras.backend.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print()\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "def create_CNN():\n",
    "    # instantiate model\n",
    "    model = Sequential()\n",
    "    # add first convolutional layer with 10 filters (dimensionality of output space)\n",
    "    model.add(Conv2D(3, kernel_size=(5, 5),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    # add 2D pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # add second convolutional layer with 20 filters\n",
    "    model.add(Conv2D(4, (6, 6), activation='relu'))\n",
    "    # apply dropout with rate 0.5\n",
    "    model.add(Dropout(0.5))\n",
    "    # add 2D pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # flatten data\n",
    "    model.add(Flatten())\n",
    "    # add a dense all-to-all relu layer\n",
    "    model.add(Dense(300,input_dim=4*14*14, activation='relu'))\n",
    "    # apply dropout with rate 0.5\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(100,input_dim=300, activation='relu'))\n",
    "    # apply dropout with rate 0.5\n",
    "    model.add(Dropout(0.5))\n",
    "    # soft-max layer\n",
    "    model.add(Dense(num_classes, input_dim=100, activation='softmax'))\n",
    "    \n",
    "    # compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer='Adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating CNN\n",
      "done creating CNN!\n",
      "train begin...\n",
      "Train on 6985 samples, validate on 1747 samples\n",
      "Epoch 1/75\n",
      "6985/6985 [==============================] - 7s 1ms/step - loss: 2.2772 - accuracy: 0.1150 - val_loss: 2.2417 - val_accuracy: 0.1448\n",
      "Epoch 2/75\n",
      "6985/6985 [==============================] - 8s 1ms/step - loss: 2.2217 - accuracy: 0.1605 - val_loss: 2.1726 - val_accuracy: 0.2221\n",
      "Epoch 3/75\n",
      "6985/6985 [==============================] - 8s 1ms/step - loss: 2.1326 - accuracy: 0.2052 - val_loss: 2.0255 - val_accuracy: 0.3148\n",
      "Epoch 4/75\n",
      "6985/6985 [==============================] - 8s 1ms/step - loss: 2.0426 - accuracy: 0.2503 - val_loss: 2.0283 - val_accuracy: 0.2931\n",
      "Epoch 5/75\n",
      "6985/6985 [==============================] - 8s 1ms/step - loss: 1.9862 - accuracy: 0.2697 - val_loss: 1.9931 - val_accuracy: 0.3091\n",
      "Epoch 6/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.9516 - accuracy: 0.2862 - val_loss: 1.9329 - val_accuracy: 0.3188\n",
      "Epoch 7/75\n",
      "6985/6985 [==============================] - 8s 1ms/step - loss: 1.9275 - accuracy: 0.2926 - val_loss: 1.9199 - val_accuracy: 0.3337\n",
      "Epoch 8/75\n",
      "6985/6985 [==============================] - 8s 1ms/step - loss: 1.8929 - accuracy: 0.3104 - val_loss: 1.8980 - val_accuracy: 0.3331\n",
      "Epoch 9/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.8710 - accuracy: 0.3200 - val_loss: 1.8966 - val_accuracy: 0.3412\n",
      "Epoch 10/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.8525 - accuracy: 0.3271 - val_loss: 1.9212 - val_accuracy: 0.3337\n",
      "Epoch 11/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.8231 - accuracy: 0.3384 - val_loss: 1.9007 - val_accuracy: 0.3532\n",
      "Epoch 12/75\n",
      "6985/6985 [==============================] - 8s 1ms/step - loss: 1.8069 - accuracy: 0.3443 - val_loss: 1.8954 - val_accuracy: 0.3515\n",
      "Epoch 13/75\n",
      "6985/6985 [==============================] - 8s 1ms/step - loss: 1.8261 - accuracy: 0.3404 - val_loss: 1.8972 - val_accuracy: 0.3572\n",
      "Epoch 14/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.7680 - accuracy: 0.3595 - val_loss: 1.8754 - val_accuracy: 0.3555\n",
      "Epoch 15/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.7417 - accuracy: 0.3735 - val_loss: 1.8686 - val_accuracy: 0.3703\n",
      "Epoch 16/75\n",
      "6985/6985 [==============================] - 8s 1ms/step - loss: 1.7318 - accuracy: 0.3739 - val_loss: 1.8834 - val_accuracy: 0.3486\n",
      "Epoch 17/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.7148 - accuracy: 0.3821 - val_loss: 1.8973 - val_accuracy: 0.3618\n",
      "Epoch 18/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.6770 - accuracy: 0.3878 - val_loss: 1.8916 - val_accuracy: 0.3910\n",
      "Epoch 19/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.6480 - accuracy: 0.3994 - val_loss: 1.9216 - val_accuracy: 0.3835\n",
      "Epoch 20/75\n",
      "6985/6985 [==============================] - 8s 1ms/step - loss: 1.6268 - accuracy: 0.4136 - val_loss: 1.9144 - val_accuracy: 0.3887\n",
      "Epoch 21/75\n",
      "6985/6985 [==============================] - 8s 1ms/step - loss: 1.6269 - accuracy: 0.4074 - val_loss: 1.9075 - val_accuracy: 0.4116\n",
      "Epoch 22/75\n",
      "6985/6985 [==============================] - 8s 1ms/step - loss: 1.6265 - accuracy: 0.4115 - val_loss: 1.8964 - val_accuracy: 0.3875\n",
      "Epoch 23/75\n",
      "6985/6985 [==============================] - 8s 1ms/step - loss: 1.6010 - accuracy: 0.4226 - val_loss: 1.9495 - val_accuracy: 0.4121\n",
      "Epoch 24/75\n",
      "6985/6985 [==============================] - 8s 1ms/step - loss: 1.5626 - accuracy: 0.4366 - val_loss: 1.9396 - val_accuracy: 0.4139\n",
      "Epoch 25/75\n",
      "6985/6985 [==============================] - 8s 1ms/step - loss: 1.5349 - accuracy: 0.4465 - val_loss: 1.9151 - val_accuracy: 0.4345\n",
      "Epoch 26/75\n",
      "6985/6985 [==============================] - 8s 1ms/step - loss: 1.5342 - accuracy: 0.4475 - val_loss: 1.8822 - val_accuracy: 0.4213\n",
      "Epoch 27/75\n",
      "6985/6985 [==============================] - 8s 1ms/step - loss: 1.5148 - accuracy: 0.4547 - val_loss: 1.9700 - val_accuracy: 0.4299\n",
      "Epoch 28/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.4915 - accuracy: 0.4577 - val_loss: 1.9778 - val_accuracy: 0.4327\n",
      "Epoch 29/75\n",
      "6985/6985 [==============================] - 8s 1ms/step - loss: 1.4893 - accuracy: 0.4611 - val_loss: 1.9884 - val_accuracy: 0.4230\n",
      "Epoch 30/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.4606 - accuracy: 0.4815 - val_loss: 2.0205 - val_accuracy: 0.4264\n",
      "Epoch 31/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.4473 - accuracy: 0.4860 - val_loss: 2.0139 - val_accuracy: 0.4293\n",
      "Epoch 32/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.4366 - accuracy: 0.4893 - val_loss: 1.9579 - val_accuracy: 0.4631\n",
      "Epoch 33/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.4244 - accuracy: 0.4879 - val_loss: 1.9420 - val_accuracy: 0.4728\n",
      "Epoch 34/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.4523 - accuracy: 0.4724 - val_loss: 2.0462 - val_accuracy: 0.4219\n",
      "Epoch 35/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.4069 - accuracy: 0.4988 - val_loss: 1.9888 - val_accuracy: 0.4287\n",
      "Epoch 36/75\n",
      "6985/6985 [==============================] - 10s 1ms/step - loss: 1.3643 - accuracy: 0.5112 - val_loss: 2.0938 - val_accuracy: 0.4591\n",
      "Epoch 37/75\n",
      "6985/6985 [==============================] - 10s 1ms/step - loss: 1.3952 - accuracy: 0.5054 - val_loss: 2.0633 - val_accuracy: 0.4768\n",
      "Epoch 38/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.3632 - accuracy: 0.5122 - val_loss: 2.0705 - val_accuracy: 0.4768\n",
      "Epoch 39/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.3351 - accuracy: 0.5247 - val_loss: 2.0852 - val_accuracy: 0.4751\n",
      "Epoch 40/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.3054 - accuracy: 0.5413 - val_loss: 2.1089 - val_accuracy: 0.4345\n",
      "Epoch 41/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.3502 - accuracy: 0.5256 - val_loss: 2.1322 - val_accuracy: 0.4493\n",
      "Epoch 42/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.3293 - accuracy: 0.5344 - val_loss: 2.0447 - val_accuracy: 0.4282\n",
      "Epoch 43/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.2850 - accuracy: 0.5427 - val_loss: 2.0768 - val_accuracy: 0.4482\n",
      "Epoch 44/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.2872 - accuracy: 0.5426 - val_loss: 2.1512 - val_accuracy: 0.4270\n",
      "Epoch 45/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.2656 - accuracy: 0.5519 - val_loss: 2.0668 - val_accuracy: 0.4900\n",
      "Epoch 46/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.2732 - accuracy: 0.5601 - val_loss: 2.1037 - val_accuracy: 0.4562\n",
      "Epoch 47/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.2724 - accuracy: 0.5558 - val_loss: 2.0794 - val_accuracy: 0.4694\n",
      "Epoch 48/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.2553 - accuracy: 0.5578 - val_loss: 2.1623 - val_accuracy: 0.4751\n",
      "Epoch 49/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.2553 - accuracy: 0.5559 - val_loss: 2.1398 - val_accuracy: 0.4860\n",
      "Epoch 50/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.2381 - accuracy: 0.5658 - val_loss: 2.1496 - val_accuracy: 0.4539\n",
      "Epoch 51/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.2248 - accuracy: 0.5701 - val_loss: 2.1363 - val_accuracy: 0.4694\n",
      "Epoch 52/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.2070 - accuracy: 0.5768 - val_loss: 2.2308 - val_accuracy: 0.4619\n",
      "Epoch 53/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.1694 - accuracy: 0.5878 - val_loss: 2.2847 - val_accuracy: 0.4745\n",
      "Epoch 54/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.1852 - accuracy: 0.5903 - val_loss: 2.1424 - val_accuracy: 0.4637\n",
      "Epoch 55/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.1899 - accuracy: 0.5818 - val_loss: 2.2033 - val_accuracy: 0.4219\n",
      "Epoch 56/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.1920 - accuracy: 0.5860 - val_loss: 2.1630 - val_accuracy: 0.4671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.1572 - accuracy: 0.5960 - val_loss: 2.2493 - val_accuracy: 0.4505\n",
      "Epoch 58/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.1723 - accuracy: 0.6046 - val_loss: 2.1469 - val_accuracy: 0.5072\n",
      "Epoch 59/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.2000 - accuracy: 0.5825 - val_loss: 2.2985 - val_accuracy: 0.4390\n",
      "Epoch 60/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.1836 - accuracy: 0.5865 - val_loss: 2.2671 - val_accuracy: 0.4762\n",
      "Epoch 61/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.1640 - accuracy: 0.6033 - val_loss: 2.2792 - val_accuracy: 0.4591\n",
      "Epoch 62/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.1387 - accuracy: 0.5948 - val_loss: 2.3406 - val_accuracy: 0.4591\n",
      "Epoch 63/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.1156 - accuracy: 0.6109 - val_loss: 2.2987 - val_accuracy: 0.4625\n",
      "Epoch 64/75\n",
      "6985/6985 [==============================] - 8s 1ms/step - loss: 1.1267 - accuracy: 0.5994 - val_loss: 2.2899 - val_accuracy: 0.4699\n",
      "Epoch 65/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.1268 - accuracy: 0.6084 - val_loss: 2.3254 - val_accuracy: 0.4677\n",
      "Epoch 66/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.1598 - accuracy: 0.5948 - val_loss: 2.3694 - val_accuracy: 0.4785\n",
      "Epoch 67/75\n",
      "6985/6985 [==============================] - 10s 1ms/step - loss: 1.1287 - accuracy: 0.6070 - val_loss: 2.3343 - val_accuracy: 0.4808\n",
      "Epoch 68/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.1218 - accuracy: 0.6136 - val_loss: 2.2676 - val_accuracy: 0.4780\n",
      "Epoch 69/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.1036 - accuracy: 0.6263 - val_loss: 2.3219 - val_accuracy: 0.4825\n",
      "Epoch 70/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.0679 - accuracy: 0.6298 - val_loss: 2.3975 - val_accuracy: 0.5197\n",
      "Epoch 71/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.0688 - accuracy: 0.6314 - val_loss: 2.4125 - val_accuracy: 0.4865\n",
      "Epoch 72/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.0861 - accuracy: 0.6239 - val_loss: 2.2850 - val_accuracy: 0.4728\n",
      "Epoch 73/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.1120 - accuracy: 0.6109 - val_loss: 2.3291 - val_accuracy: 0.4774\n",
      "Epoch 74/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.0714 - accuracy: 0.6235 - val_loss: 2.3662 - val_accuracy: 0.4551\n",
      "Epoch 75/75\n",
      "6985/6985 [==============================] - 9s 1ms/step - loss: 1.0672 - accuracy: 0.6256 - val_loss: 2.3643 - val_accuracy: 0.4917\n",
      "1747/1747 [==============================] - 1s 462us/step\n",
      "\n",
      "Test loss: 2.364300592531118\n",
      "Test accuracy: 0.49170005321502686\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "batch_size = 64\n",
    "epochs = 75\n",
    "\n",
    "# create the deep conv net\n",
    "print('creating CNN')\n",
    "model_CNN=create_CNN()\n",
    "print('done creating CNN!')\n",
    "\n",
    "print('train begin...')\n",
    "# train CNN\n",
    "\n",
    "model_CNN.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n",
    "\n",
    "# evaliate model\n",
    "score = model_CNN.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1747/1747 [==============================] - 1s 328us/step\n",
      "\n",
      "Test loss: 2.116617216747286\n",
      "Test accuracy: 0.45392102003097534\n"
     ]
    }
   ],
   "source": [
    "score = model_CNN.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
